---
runme:
  id: fleetfolio-eaa-pentest-lite
  name: "Fleetfolio EAA – Pentest Lite (Authorized)"
  version: "2.0.0"
  maintainer: "Fleetfolio Team"
  description: "Lightweight, authorized, container-run external asset assessment with structured artifacts."
---
This Runme runbook performs an **authorized, lightweight external asset assessment** inside an OWASP Nightingale container
(default base: `rajanagori/nightingale:latest`). It orchestrates a chain of reconnaissance and validation tools to
discover domains, resolve DNS, probe for web services, scan ports, fingerprint technologies, check TLS certificates, and run
targeted vulnerability checks. All artifacts are stored under `/var/fleetfolio/eaa/<tool>/…` in structured formats such as
JSON, JSONL, XML, or plain text.

The runbook is meant to be **safe, idempotent, and scope-aware**, honoring exclusions and customer authorization.

All the packages come from `Debian`. When they don’t come from Debian, we use `Homebrew`. If not available in Homebrew, we use `eget`. If none of these work, we install it directly using the runtime installation instructions.

## Roadmap

- [ ] Introduce [Rustscan](https://github.com/bee-san/RustScan) for Ultra-fast port scanner with intelligent rate limiting
- [ ] Introduce [Masscan](https://www.kali.org/tools/masscan/) for High-speed Internet-scale port scanning with banner grabbing
- [ ] Introduce [AutoRecon](https://github.com/Tib3rius/AutoRecon) for Comprehensive automated reconnaissance with 35+ parameters
- [ ] Introduce [Amass](https://github.com/owasp-amass/amass) for Advanced subdomain enumeration and OSINT gathering
- [ ] Introduce [Fierce](https://github.com/mschwager/fierce) for DNS reconnaissance and zone transfer testing
- [ ] Introduce [DNSEnum](https://www.kali.org/tools/dnsenum/) for DNS information gathering and subdomain brute forcing
- [ ] Introduce [TheHarvester](https://github.com/laramies/theHarvester) for Email and subdomain harvesting from multiple sources

## Manual Installation of Kali Linux in VirtualBox

This guide will help you manually install **Kali Linux** in **VirtualBox** on your host machine.

### Prerequisites

- **VirtualBox**: [Download VirtualBox](https://www.virtualbox.org/wiki/Downloads)
- **Kali Linux Virtual Machine**: [Download Kali Linux VM](https://www.kali.org/get-kali/#kali-platforms) (VirtualBox, 3.3 GB, `.7z` file)
- **WinRAR** or **7-Zip** for extraction: [Download WinRAR](https://www.win-rar.com/download.html?&L=0) (recommended)

#### Steps

1. **Download Kali Linux**

   - Select **Virtual Machine** and then **VirtualBox (3.3 GB)**.
   - The file will be in `.7z` format.

2. **Download and install VirtualBox**

   - Open [VirtualBox Downloads](https://www.virtualbox.org/wiki/Downloads) and install it on your host machine.

3. **Extract Kali Linux VM**

   - Use **WinRAR** or **7-Zip** to extract the `.7z` file to your **Downloads** folder.
   - There will be two files: A `.vdi` file (orange icon) and one `.vbox file` (blue icon). Double-click on the `.vbox` file to automatically import the Kali Linux Machine into VirtualBox.

4. **Configure the Virtual Machine**

   - Set **Base Memory** to `4096 MB` (recommended).
   - Set **Processor Cores** to `2–3` (recommended).
   - Start the virtual machine.

5. **Login**

- Default credentials:

```text { ignore=true }
Username: kali
Password: kali
```

6. **Switch to Root User**

- Open the terminal and type:

```bash { ignore=true }
sudo su
```

- This will give you root privileges (most privileged user).

7. **Update the System**

- In the terminal, run:

```bash { ignore=true }
sudo apt update && sudo apt upgrade -y && sudo apt full-upgrade -y
```

- This will ensure your system is fully updated and prevent errors when installing tools.

**Note:** Always use updated VirtualBox and Kali Linux versions to avoid compatibility issues.

## Fixing Errors

If you encounter any errors while running the above system update commands, follow these steps:

```bash { ignore=true }
sudo sed -i 's|http://http.kali.org|https://http.kali.org|' /etc/apt/sources.list
```

Then run the following commands one by one:

```bash { ignore=true }
sudo apt-get clean && sudo apt-get update --fix-missing
```

Then run the system update command again:

```bash { ignore=true }
sudo apt update && sudo apt upgrade -y && sudo apt full-upgrade -y
```

---

### Prerequisite Dependency

**Homebrew**

```bash { ignore=true }
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)" && echo >> /home/kali/.zshrc && echo 'eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"' >> /home/kali/.zshrc && eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)" && sudo apt-get install -y build-essential && brew install gcc
```

Note : Run this command inside a non-root user terminal. You will be prompted to enter the password, and then press Enter again to continue

**Go**

```bash { ignore=true }
sudo apt install golang-go -y
```

---

#### Install [RUNME](https://github.com/runmedev/runme)

To get started with Runme on Linux, the recommended method of installation is using Homebrew, a popular package manager that simplifies the installation process. First, ensure your Homebrew is up to date to avoid any compatibility issues:

```bash { ignore=true }
brew update && brew install runme
```

#### Install [Varlock](https://github.com/dmno-dev/varlock)

Varlock is a tool for managing and validating environment variables using a schema file, ensuring all required variables are correctly set before running commands. It adds consistency, security, and reliability to workflows that depend on .env files.
To install:

```bash { ignore=true }
brew install dmno-dev/tap/varlock
```

Homebrew-installed tools not accessible when switching to root user (Solution: Add Homebrew to root’s shell environment)

```bash { ignore=true }
sudo su && echo 'eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"' >> /root/.zshrc && eval "$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)"
```

## Tools Required and Their Installation Steps

#### Whatweb, Nmap, Openssl, wafw00f, sqlmap are Pre-installed in kali linux

```bash { ignore=true }
sudo apt install -y subfinder dnsx httpx-toolkit naabu nuclei xq jq dirsearch testssl.sh && \
go install github.com/projectdiscovery/katana/cmd/katana@latest && sudo cp ~/go/bin/katana /bin/  && \
go install github.com/projectdiscovery/tlsx/cmd/tlsx@latest && sudo cp ~/go/bin/tlsx /bin/
```

## Run Varlock with Runme to Execute Fleetfolio Pentest Workflow

```bash { ignore=true }
varlock init && varlock load && varlock run -- runme run --filename="fleetfolio-eaa-pentest-lite.runme.md" --all
```

Note: Make sure you are the root user and inside the eaa directory before running the above command. Then, press "y" twice to ensure that the environment variables are declared by Varlock

## Environment Variables

- `OPSFOLIO_EAA_HOME` (default: `.fleetfolio/eaa` in current directory)
- `OPSFOLIO_EAA_TENANT_ID` – tenant IDs, separated by commas or spaces
- `OPSFOLIO_EAA_TENANT_NAME` – tenant names, separated by commas or spaces
- `OPSFOLIO_EAA_DOMAINS` – comma- or space-separated domains
- `OPSFOLIO_EAA_IP_RANGES` – comma- or space-separated IPs/CIDRs
- `OPSFOLIO_EAA_KEY_URLS` – comma- or space-separated URLs/APIs
- `OPSFOLIO_EAA_EXCLUDES` – comma- or space-separated exclusions
- `OPSFOLIO_EAA_RATE_LIMIT` (default: 200)
- `OPSFOLIO_EAA_CONCURRENCY` (default: 50)
- `OPSFOLIO_EAA_NAABU_PORTS` (default: top-100)
- `OPSFOLIO_EAA_NUCLEI_TEMPLATES` (default: cves,default)

# Initialization and Logging

The runbook begins by creating a working directory for session data, evidence, and logs. It snapshots all Fleetfolio-related
environment variables so that the test configuration is preserved for auditability. The master log file is written to
`$OPSFOLIO_EAA_HOME/runbook.log`.

```bash { name=init }
set -euo pipefail; IFS=$'\n\t'
: "${OPSFOLIO_EAA_HOME:=$(pwd)/.fleetfolio/eaa}"
mkdir -p "$OPSFOLIO_EAA_HOME/.session"
LOG="$OPSFOLIO_EAA_HOME/runbook.log"

(env | grep ^OPSFOLIO_EAA_ || true) > "$OPSFOLIO_EAA_HOME/arguments.env"
echo "[init] Snapshot written to $OPSFOLIO_EAA_HOME/arguments.env" | tee -a "$LOG"
```

Artifacts: `$OPSFOLIO_EAA_HOME/arguments.env` (environment variables in `key=value` format) and the master runbook log
at `$OPSFOLIO_EAA_HOME/runbook.log`.

# Scope Normalization

Environment variables are convenient but not ideal for tool chaining. Here we normalize them into newline-delimited files so
each tool can consume scope easily.

```bash { name=normalize_scope }
set -euo pipefail; IFS=$'\n\t'

# Load .env properly
if [ -f .env ]; then
  set -a   # automatically export all variables
  source .env
  set +a
fi

# Ensure OPSFOLIO_EAA_HOME is set
: "${OPSFOLIO_EAA_HOME:?OPSFOLIO_EAA_HOME must be set in .env}"
export OPSFOLIO_EAA_HOME="$OPSFOLIO_EAA_HOME/$(date +'%Y-%m-%d-%H-%M-%S')"
export OPSFOLIO_EAA_SESSION_HOME="$OPSFOLIO_EAA_HOME/.session"
mkdir -p "$OPSFOLIO_EAA_SESSION_HOME" 
env > $OPSFOLIO_EAA_SESSION_HOME/.env
cp fleetfolio-eaa-pentest-lite.runme.md $OPSFOLIO_EAA_SESSION_HOME

echo "${OPSFOLIO_EAA_DOMAINS:-}"   | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/domains.txt"
echo "${OPSFOLIO_EAA_SUBDOMAINS:-}"| tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/subdomains.txt"
echo "${OPSFOLIO_EAA_IP_RANGES:-}" | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/ip_ranges.txt"
echo "${OPSFOLIO_EAA_KEY_URLS:-}"  | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt"
echo "${OPSFOLIO_EAA_EXCLUDES:-}"  | tr ', ' '\n' | sed '/^$/d' > "$OPSFOLIO_EAA_SESSION_HOME/excludes.txt"
```

Artifacts: text files under `$OPSFOLIO_EAA_HOME/.session/` for domains, IP ranges, key URLs, and excludes.

# Subfinder – Discovering Subdomains

[Subfinder](https://github.com/projectdiscovery/subfinder) A subdomain discovery tool that uses passive online sources to quickly enumerate subdomains for a given domain. It’s widely used in reconnaissance to map the attack surface.  
**Use Cases:**

- Discovering subdomains of a target organization during reconnaissance.
- Expanding attack surface before vulnerability scanning.
- Validating scope in bug bounty programs.

```bash { name=subfinder }
set -euo pipefail
IFS=$'\n\t'

OUT="$OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl"
mkdir -p "$(dirname "$OUT")"

DOMAINS_FILE="$OPSFOLIO_EAA_SESSION_HOME/domains.txt"
SUBDOMAINS_FILE="$OPSFOLIO_EAA_SESSION_HOME/subdomains.txt"

# Prepare input files if they exist in .env
if [ -n "${OPSFOLIO_EAA_DOMAINS:-}" ]; then
  echo "$OPSFOLIO_EAA_DOMAINS" | tr ' ,;' '\n' > "$DOMAINS_FILE"
fi

if [ -n "${OPSFOLIO_EAA_SUBDOMAINS:-}" ]; then
  echo "$OPSFOLIO_EAA_SUBDOMAINS" | tr ' ,;' '\n' > "$SUBDOMAINS_FILE"
fi

# Case 1: Domains present → run subfinder as usual
if [ -s "$DOMAINS_FILE" ]; then
  while read -r DOMAIN; do
    BASE=$(echo "$DOMAIN" | awk -F. '{print $(NF-1)"."$NF}')
    if [ "$DOMAIN" = "$BASE" ]; then
      subfinder -d "$DOMAIN" -oJ -silent >> "$OUT" || true
    else
      echo "$DOMAIN" | dnsx -resp -silent | jq -R '{host:.}' >> "$OUT" || true
    fi
  done < "$DOMAINS_FILE"

# Case 2: No domains, but subdomains provided → just save them
elif [ -s "$SUBDOMAINS_FILE" ]; then
  while read -r SUB; do
    echo "$SUB" | jq -R '{host:.}' >> "$OUT"
  done < "$SUBDOMAINS_FILE"
fi

```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl`, one JSON record per subdomain discovered.

# dnsx – Resolving Hosts

[dnsx](https://github.com/projectdiscovery/dnsx) A fast and flexible DNS toolkit for running DNS queries. It can resolve hostnames, filter responses, and validate records, making it useful for verifying subdomain discoveries.  
**Use Cases:**

- Resolving subdomains found via Subfinder to check if they are alive.
- Performing DNS record lookups (A, CNAME, TXT, MX, etc.).
- Filtering valid domains from a large list.

```bash { name=dnsx }
set -euo pipefail; IFS=$'\n\t'
OUT="$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl"
mkdir -p "$(dirname "$OUT")"

jq -r 'select(.host!=null) | .host' $OPSFOLIO_EAA_HOME/subfinder/subfinder.jsonl \
  | sed 's/ .*//' \
  | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
  | dnsx -json -silent -o "$OUT" || true
```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl` containing resolved IPs, CNAMEs, and other DNS data.

# httpx-toolkit – Probing Web Services

[httpx-toolkit](https://www.kali.org/tools/httpx-toolkit/) A fast HTTP toolkit that probes web servers to collect information such as status codes, titles, technologies, TLS details, redirects, and response headers. It helps identify live hosts and gather intelligence.  
**Use Cases:**

- Checking which discovered subdomains are live.
- Collecting metadata (status codes, titles, headers, TLS details).
- Identifying web technologies for further exploitation.

```bash { name=httpx }
set -euo pipefail
IFS=$'\n\t'

OUT="$OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl"

# Create the output directory if it does not exist
mkdir -p "$(dirname "$OUT")"

jq -r .host $OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl \
  | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
  > targets.txt || true

cat "$$OPSFOLIO_EAA_HOME/key_urls.txt" >> targets.txt || true

httpx-toolkit -l targets.txt -json -silent \
  -rl "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -threads "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -o "$OUT"

```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/httpx/httpx-toolkit.jsonl` with fields like URL, status code, title, webserver header.

# WhatWeb – Fingerprinting Technologies

[WhatWeb](https://github.com/urbanadventurer/WhatWeb) A web scanner that identifies websites’ technologies, frameworks, CMS, server details, and other metadata. It’s useful for fingerprinting applications during reconnaissance.  
**Use Cases:**

- Detecting CMS (e.g., WordPress, Joomla, Drupal) in use.
- Identifying server-side technologies (Apache, Nginx, PHP, etc.).
- Profiling web applications for potential vulnerabilities.

```bash { name=whatweb }
#!/bin/bash
set -euo pipefail
IFS=$'\n\t'

mkdir -p $OPSFOLIO_EAA_HOME/whatweb

# Extract URLs, remove excluded ones, remove duplicates
jq -r .url $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
  | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
  | sort -u \
  | while read -r url; do
      safe=$(echo "$url" | sed 's#[/:?&=]#_#g')
      whatweb --log-json="$OPSFOLIO_EAA_HOME/whatweb/$safe.json" "$url" || true
    done

```

Artifacts: per-target JSON files under `$OPSFOLIO_EAA_HOME/whatweb/whatweb.jsonl` with detected technologies.
The way to detect anomalies using WhatWeb findings include:

- Refer [whatweb-security-engineer.ctxe.md](./whatweb-security-engineer.ctxe.md).

# Naabu – Scanning Open Ports

[Naabu](https://github.com/projectdiscovery/naabu) A fast port scanner written in Go. It can scan large IP ranges to identify open ports, serving as a lightweight and high-performance alternative to traditional scanners.  
**Use Cases:**

- Discovering open ports on a target system.
- Identifying exposed services (HTTP, SSH, FTP, etc.).
- Feeding live ports into service enumeration tools like Nmap.

```bash { name=naabu }
set -euo pipefail
IFS=$'\n\t'

# Ensure the output directory exists
mkdir -p $OPSFOLIO_EAA_HOME/naabu

jq -r .host $OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl \
  | grep -v -F -f "$$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
  > naabu_hosts.txt || true

naabu -list naabu_hosts.txt -json -silent \
  -top-ports "${OPSFOLIO_EAA_NAABU_PORTS#top-}" \
  -rate "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -c "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -o $OPSFOLIO_EAA_HOME/naabu/naabu.jsonl

```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/naabu/naabu.jsonl` with IP and port fields.

# Nmap – Service Enumeration

[Nmap](https://nmap.org/) One of the most popular and versatile network scanning tools. It detects open ports, services, versions, and even operating systems on target systems.  
**Use Cases:**

- Performing comprehensive port scanning and service detection.
- Detecting operating systems and service versions.
- Running vulnerability detection scripts (via NSE).

```bash { name=nmap }
set -euo pipefail
IFS=$'\n\t'

mkdir -p $OPSFOLIO_EAA_HOME/nmap

# Extract only IPs (unique)
jq -r .ip $OPSFOLIO_EAA_HOME/naabu/naabu.jsonl | sort -u > $OPSFOLIO_EAA_HOME/nmap/nmap_targets.txt

# Run nmap on those hosts
nmap -sV -Pn -n -T4 -oX $OPSFOLIO_EAA_HOME/nmap/services.xml -iL $OPSFOLIO_EAA_HOME/nmap/nmap_targets.txt || true

# Convert to JSON
xq < $OPSFOLIO_EAA_HOME/nmap/services.xml > $OPSFOLIO_EAA_HOME/nmap/services.json || true
```

Artifacts: XML and JSON representations of Nmap results at `$OPSFOLIO_EAA_HOME/nmap/nmap.*`.

# OpenSSL – Inspecting TLS Certificates

[OpenSSL](https://www.openssl.org/) A robust toolkit for the Transport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols. It’s used to generate and manage keys/certificates, test SSL connections, and troubleshoot cryptographic issues.  
**Use Cases:**

- Generating SSL/TLS certificates for secure communication.
- Testing SSL handshakes and debugging HTTPS issues.
- Checking for weak or expired certificates.

```bash { name=openssl }
set -euo pipefail; IFS=$'\n\t'

# Ensure directory exists
mkdir -p $OPSFOLIO_EAA_HOME/tls

for host in $(jq -r .host $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
              | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt"); do
  safe=$(echo "$host" | sed 's#[/:]#_#g')   # sanitize filename
  echo | openssl s_client -servername "$host" -connect "$host:443" -showcerts 2>/dev/null \
        > "$OPSFOLIO_EAA_HOME/tls/$safe.txt" || true
done
```

Artifacts: plain text certificate details in `$OPSFOLIO_EAA_HOME/openssl/*.txt`.

# Nuclei – Template-Based Vulnerability Scanning

[Nuclei](https://github.com/projectdiscovery/nuclei) A fast vulnerability scanner that uses community-contributed templates to detect misconfigurations, CVEs, exposures, and other security issues. It automates large-scale scanning with customizable templates.  
**Use Cases:**

- Scanning web apps for known CVEs using templates.
- Detecting misconfigurations (e.g., exposed panels, default creds).
- Automating bug bounty reconnaissance workflows.

```bash { name=nuclei }
set -euo pipefail
IFS=$'\n\t'

# Ensure output directory exists
mkdir -p $OPSFOLIO_EAA_HOME/nuclei

# Extract only the hostnames from httpx results and save to nuclei_targets.txt
jq -r .url $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
  | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
  | sed -E 's,https?://([^/:]+).*,\1,' \
  | sort -u \
  > $OPSFOLIO_EAA_HOME/nuclei/nuclei_targets.txt || true

# Run nuclei against just the domains for CVEs
nuclei -list $OPSFOLIO_EAA_HOME/nuclei/nuclei_targets.txt -jsonl -silent \
  -rate-limit "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -c "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -tags cves \
  -o $OPSFOLIO_EAA_HOME/nuclei/nuclei_cves.jsonl || true

# Run nuclei against just the domains for misconfigurations issues
nuclei -list $OPSFOLIO_EAA_HOME/nuclei/nuclei_targets.txt -jsonl -silent \
  -rate-limit "${OPSFOLIO_EAA_RATE_LIMIT:-200}" \
  -c "${OPSFOLIO_EAA_CONCURRENCY:-50}" \
  -o $OPSFOLIO_EAA_HOME/nuclei/nuclei.jsonl || true

```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/nuclei/nuclei.jsonl` with one result per finding.

# Katana – Crawling for Endpoints

[Katana](https://github.com/projectdiscovery/katana) A powerful web crawling tool designed to discover hidden files, endpoints, and parameters. It supports modern web technologies (like JS parsing) and is useful for application mapping and content discovery.  
**Use Cases:**

- Crawling target websites to find hidden endpoints.
- Extracting URLs and parameters for fuzzing.
- Mapping web applications for deeper testing.

```bash { name=katana }
set -euo pipefail; IFS=$'\n\t'

if command -v katana >/dev/null; then
  jq -r .url $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
    | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
    > katana_targets.txt || true

  # Ensure output directory exists
  mkdir -p $OPSFOLIO_EAA_HOME/katana

  katana -list katana_targets.txt -silent -o $OPSFOLIO_EAA_HOME/katana/katana.jsonl || true
fi
```

Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/katana/katana.jsonl` listing discovered endpoints.

# tlsx – TLS Metadata Extraction

[tlsx](https://github.com/projectdiscovery/tlsx) A TLS/SSL scanner that helps analyze SSL certificates, extract metadata, and check for security issues in TLS configurations. It is valuable for identifying weak or misconfigured SSL setups.  
**Use Cases:**

- Extracting SSL certificate details from multiple hosts.
- Identifying weak TLS versions or cipher suites.
- Monitoring certificate expiration across domains.

```bash { name=tlsx }
set -euo pipefail; IFS=$'\n\t'

if command -v tlsx >/dev/null; then
  # Ensure output directory exists
  mkdir -p $OPSFOLIO_EAA_HOME/tlsx

  # Write targets inside the same folder
  jq -r .host $OPSFOLIO_EAA_HOME/httpx-toolkit/httpx-toolkit.jsonl \
    | grep -v -F -f "$OPSFOLIO_EAA_HOME/.session/excludes.txt" \
    > $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt || true

  # Only run if we have targets
  if [ -s $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt ]; then
    tlsx -list $OPSFOLIO_EAA_HOME/tlsx/tlsx_targets.txt \
         -silent \
         -o $OPSFOLIO_EAA_HOME/tlsx/tlsx.jsonl || true
  else
    echo "[INFO] No TLSX targets found"
  fi
fi
```

- Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/tlsx/tlsx.jsonl` with structured TLS details.

# Dirsearch – Directory Enumeration

[Dirsearch](https://github.com/projectdiscovery/tlsx) Dirsearch is an open-source command-line tool used for brute-forcing directories and files on web servers. It helps security testers and administrators discover hidden resources, misconfigured files, and sensitive endpoints that are not publicly linked. The tool supports multithreading, custom wordlists, recursive scans, proxy support, and can handle various HTTP methods, making it efficient for web application reconnaissance and vulnerability assessments.

Use Cases

- Hidden Path Discovery
- Exposure of Misconfigurations
- Recon in Pentesting

```bash { name=dirsearch }
set -euo pipefail; IFS=$'\n\t'

if command -v dirsearch >/dev/null; then
  OUT="$OPSFOLIO_EAA_HOME/dirsearch/dirsearch.jsonl"
  mkdir -p "$(dirname "$OUT")"

  # Create key_urls.txt from env variable
  KEY_URLS_FILE="$OPSFOLIO_EAA_HOME/.session/key_urls.txt"
  mkdir -p "$(dirname "$KEY_URLS_FILE")"
  echo "$OPSFOLIO_EAA_KEY_URLS" | tr ',' '\n' | tr ' ' '\n' > "$KEY_URLS_FILE"

  # Run dirsearch directly on key_urls.txt
  dirsearch -l "$KEY_URLS_FILE" -i 200 --format=json -o "$OUT" >/dev/null 2>&1 || true
fi
```

- Artifacts: JSONL file at `/$OPSFOLIO_EAA_HOME/dirsearch/dirsearch.jsonl` with structured TLS details.

# wafw00f – Fingerprints Web Application Firewall (WAF)

[wafw00f](https://www.kali.org/tools/wafw00f/) WAFW00F is a Web Application Firewall (WAF) fingerprinting tool. It helps security testers and penetration testers detect whether a website is protected by a WAF and, if so, identify the specific vendor or technology in use. It works by sending crafted HTTP requests and analyzing responses to determine patterns that match known WAF behaviors.

Use Cases

- Identify if a target application is protected by a WAF so that penetration testers can adjust their testing approach accordingly.
- Determine the specific WAF vendor (e.g., Cloudflare, Akamai, Imperva) to understand its protection mechanisms and known bypass techniques.
- Validate whether an organization has correctly deployed a WAF as part of regulatory compliance (e.g., PCI DSS) or general security hardening.

```bash { name=wafw00f }
set -euo pipefail; IFS=$'\n\t'

# Input and output paths
IN="$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl"
OUT="$OPSFOLIO_EAA_HOME/wafw00f/wafw00f.jsonl"

mkdir -p "$(dirname "$OUT")"

# Run wafw00f on resolved hosts with timeout
jq -r 'select(.host!=null) | .host' "$IN" \
  | sort -u \
  | while read -r host; do
      wafw00f -a -f json "$host" || true
    done > "$OUT" || true
```

- Artifacts: JSONL file at `/var/fleetfolio/eaa/wafw00f/wafw00f.jsonl` with structured TLS details.

# Testssl – SSL/TLS Security Testing Tool

[Testssl](https://github.com/testssl/testssl.sh) Testssl.sh is an open-source command-line tool used to test SSL/TLS configurations of servers.

Use Cases

- Detect weak or deprecated SSL/TLS protocols and ciphers.
- Identify SSL/TLS misconfigurations (e.g., insecure renegotiation, Heartbleed).

```bash { name=wafw00f }
#!/usr/bin/env bash
set -euo pipefail; IFS=$'\n\t'

# Input and output paths
IN="$OPSFOLIO_EAA_HOME/dnsx/dnsx.jsonl"
OUT="$OPSFOLIO_EAA_HOME/testssl/testssl.jsonl"

mkdir -p "$(dirname "$OUT")"

# Run testssl.sh on resolved hosts with timeout
jq -r 'select(.host!=null) | .host' "$IN" \
  | sort -u \
  | while read -r host; do
      testssl --jsonfile-pretty "$OUT.tmp" "$host" || true
      if [[ -f "$OUT.tmp" ]]; then
        cat "$OUT.tmp"
        rm -f "$OUT.tmp"
      fi
    done > "$OUT" || true
```

- Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/testssl/testssl.jsonl` with structured TLS details.

# Sqlmap – SSL/TLS Security Testing Tool

[Sqlmap](https://github.com/sqlmapproject/sqlmap) is an open-source penetration testing tool that automates the process of detecting and exploiting SQL injection vulnerabilities in web applications. It supports a wide range of databases and can help security testers identify and confirm database flaws quickly.

Use Cases

- Detect SQL Injection – Automatically test web applications for SQL injection vulnerabilities.
- Database Enumeration – Extract database names, tables, columns, and even data from vulnerable applications.
- Privilege Escalation & Access – Identify database users, check privileges, and attempt to gain administrative access to the backend.

```bash { name=wafw00f }
#!/usr/bin/env bash
set -euo pipefail; IFS=$'\n\t'

# Input and output paths
IN="$OPSFOLIO_EAA_SESSION_HOME/key_urls.txt"
OUT="$OPSFOLIO_EAA_HOME/sqlmap/sqlmap.jsonl"

mkdir -p "$(dirname "$OUT")"

# Run sqlmap on each URL and collect results
cat "$IN" | sort -u | while read -r url; do
    sqlmap --random-agent --batch \
           --current-user --current-db \
           -u "$url" \
           --output-dir="$OUT.tmp" || true
    if [[ -d "$OUT.tmp" ]]; then
        # Collect all sqlmap results into one JSONL
        find "$OUT.tmp" -type f -name '*.json' -exec cat {} \;
        rm -rf "$OUT.tmp"
    fi
done > "$OUT" || true
```

- Artifacts: JSONL file at `$OPSFOLIO_EAA_HOME/sqlmap/sqlmap.jsonl` with structured TLS details.

# Summary

Finally, we summarize counts of findings and provide hints for what to review next.

```bash { ignore=true }
set -euo pipefail; IFS=$'\n\t'
echo "=== Summary of Findings ==="
for f in subfinder dnsx httpx-toolkit naabu nuclei katana; do
  path="/var/fleetfolio/eaa/$f/$f.jsonl"
  if [ -s "$path" ]; then
    echo "$f: $(wc -l < $path) lines"
  fi
done
echo "WhatWeb: $(ls -1 /var/fleetfolio/eaa/whatweb/*.json 2>/dev/null | wc -l) files"
echo "Nmap: $(ls -1 /var/fleetfolio/eaa/nmap/* 2>/dev/null | wc -l) files"
echo "TLS: $(ls -1 /var/fleetfolio/eaa/tls/* 2>/dev/null | wc -l) files"

echo
echo "Next steps:"
echo " - Review nuclei results by severity and template."
echo " - Inspect WhatWeb outputs for outdated technologies."
echo " - Validate service exposure in nmap JSON output."
echo " - Audit TLS metadata in both OpenSSL text and tlsx JSONL."
echo " - Cross-check discovered assets against official inventories."
```

Artifacts: summary counts printed to console; references to JSONL, JSON, XML, and plaintext outputs.

# Analyst’s Guide to Interpreting Artifacts

This appendix provides practical advice for reviewing the artifacts generated by each tool. It is meant for analysts who may
not be familiar with the nuances of every tool but need to make sense of the outputs.

## Subfinder (`subfinder.jsonl`)

Each line is a JSON object with a `host` field and the `source` where it was discovered. Analysts should look for:

- Subdomains that are unexpected or unmanaged.
- Entries that do not resolve later in dnsx, which may indicate legacy or abandoned records.

## dnsx (`dnsx.jsonl`)

DNS resolution results will include IPs (A/AAAA records), CNAMEs, and other metadata. Analysts should:

- Verify that IPs map to owned infrastructure.
- Flag any pointing to cloud or third-party networks that might be unmanaged.

## httpx-toolkit (`httpx-toolkit.jsonl`)

Contains metadata for live web services: status codes, titles, server headers. Analysts should:

- Look for sensitive endpoints (e.g., admin panels, login portals).
- Pay attention to unusual server headers or technologies that don’t align with policy.

## WhatWeb (`whatweb/*.json`)

Per-target JSON files list detected plugins/technologies. Analysts should:

- Identify outdated CMS or frameworks (e.g., old WordPress, Joomla).
- Cross-check detected versions against known vulnerabilities.

## Naabu (`naabu.jsonl`)

JSON lines listing IPs and open ports. Analysts should:

- Spot unexpected open ports (e.g., databases, RDP, SSH exposed externally).
- Focus on high-risk services like SMB, Telnet, or legacy protocols.

## Nmap (`services.xml`, `services.json`)

Provides enriched service banners and versions. Analysts should:

- Confirm the accuracy of Naabu findings.
- Evaluate service versions for end-of-life software.

## OpenSSL (`tls/*.txt`)

Raw transcripts of TLS handshakes and certificate chains. Analysts should:

- Check expiry dates, SAN entries, and certificate issuers.
- Flag self-signed or weakly signed certificates.

## Nuclei (`nuclei.jsonl`)

Each JSON line represents a finding matched against a template. Analysts should:

- Sort by severity to prioritize triage.
- Validate important findings manually before reporting.

## Katana (`katana.jsonl`)

Lists discovered web endpoints through crawling. Analysts should:

- Look for API endpoints, hidden admin paths, or sensitive resources.
- Cross-reference endpoints against vulnerability scan coverage.

## tlsx (`tlsx.jsonl`)

Structured TLS metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## Dirsearch (`dirsearch.jsonl`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## wafw00f (`wafw00f.jsonl`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## Testssl (`testssl.jsonl`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

## Sqlmap (`sqlmap.jsonl`)

Structured drsearch metadata such as cipher suites and certificate details. Analysts should:

- Use this to complement OpenSSL outputs with machine-friendly JSON data.
- Review for weak ciphers or deprecated protocol versions.

---

This guide should be used alongside the summary step to quickly assess which artifacts need deeper analysis.



